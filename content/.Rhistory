library(tidyverse)
library(ROCR)
install.packages("ROCR")
library(ROCR)
dengue <- read.csv("https://sta279-s22.github.io/labs/dengue.csv")
m1 <- glm(Dengue ~ Age + WBC + PLT, data = dengue,
family = binomial)
m2 <- glm(Dengue ~  Age + WBC + PLT + BMI + HCT + Temperature,
data = dengue, family = binomial)
m1$deviance - m1$null.deviance
m1$null.deviance - m1$deviance
print("The change in deviance for model 1 is ", m1$null.deviance - m1$deviance)
print("The change in deviance for model 2 is ", round(m2$null.deviance, 2))
print(paste("The change in deviance for model 1 is ", round(m1$null.deviance - m1$deviance, 2)))
print(paste("The change in deviance for model 2 is ", round(m2$null.deviance - m2$deviance, 2)))
# calculating performance metrics using the ROCR package
## TPR vs. FPR for model 1
pred1 <- prediction(m1$fitted.values, m1$y)
perf1 <- performance(pred1,"tpr","fpr")
## TPR vs. FPR for model 2
pred2 <- prediction(m2$fitted.values, m2$y)
perf2 <- performance(pred2,"tpr","fpr")
## Plot both ROC curves on the same graph
data.frame(fpr = c(perf1@x.values[[1]], perf2@x.values[[1]]),
tpr = c(perf1@y.values[[1]], perf2@y.values[[1]]),
model = c(rep("Model 1", length(perf1@x.values[[1]])),
rep("Model 2", length(perf2@x.values[[1]])))) |>
ggplot(aes(x = fpr, y = tpr, color = model)) +
geom_line() +
geom_abline(slope = 1, intercept = 0, lty = 2) +
labs(x = "False positive rate (1 - Specificity)",
y = "True positive rate (Sensitivity)") +
theme_classic()
## calculate AUC values
performance(pred1, "auc")@y.values # AUC for model 1
performance(pred2, "auc")@y.values # AUC for model 2
set.seed(712)
n <- 1000
d <- 6
X <- matrix(rnorm(d*n), nrow=n)
p <- exp(-0.5 + X %*% c(0.2, 0.2, 0.2, 0, 0, 0))/(
1 + exp(-0.5 + X %*% c(0.2, 0.2, 0.2, 0, 0, 0))
)
y <- rbinom(n, 1, p)
m1 <- glm(y ~ X[,1:3], family = binomial)
m2 <- glm(y ~ X, family = binomial)
print(paste("The deviance for model 1 is ", round(m1$deviance,2)))
print(paste("The deviance for model 2 is ", round(m2$deviance,2)))
# calculating performance metrics using the ROCR package
## TPR vs. FPR for model 1
pred1 <- prediction(m1$fitted.values, m1$y)
perf1 <- performance(pred1,"tpr","fpr")
## TPR vs. FPR for model 2
pred2 <- prediction(m2$fitted.values, m2$y)
perf2 <- performance(pred2,"tpr","fpr")
## Plot both ROC curves on the same graph
data.frame(fpr = c(perf1@x.values[[1]], perf2@x.values[[1]]),
tpr = c(perf1@y.values[[1]], perf2@y.values[[1]]),
model = c(rep("Model 1", length(perf1@x.values[[1]])),
rep("Model 2", length(perf2@x.values[[1]])))) |>
ggplot(aes(x = fpr, y = tpr, color = model)) +
geom_line() +
geom_abline(slope = 1, intercept = 0, lty = 2) +
labs(x = "False positive rate (1 - Specificity)",
y = "True positive rate (Sensitivity)") +
theme_classic()
## calculate AUC values
performance(pred1, "auc")@y.values # AUC for model 1
performance(pred2, "auc")@y.values # AUC for model 2
X_new <- matrix(rnorm(d*n), nrow=n)
p_new <- exp(-0.5 + X_new %*% c(0.2, 0.2, 0.2, 0, 0, 0))/(
1 + exp(-0.5 + X_new %*% c(0.2, 0.2, 0.2, 0, 0, 0))
)
y_new <- rbinom(n, 1, p_new)
# predictions on new observations
phat_m1 <- exp(m1$coefficients[1] + X_new[,1:3] %*% m1$coefficients[2:4])/(
1 + exp(m1$coefficients[1] + X_new[,1:3] %*% m1$coefficients[2:4])
)
phat_m2 <- exp(m2$coefficients[1] + X_new %*% m2$coefficients[2:7])/(
1 + exp(m2$coefficients[1] + X_new %*% m2$coefficients[2:7])
)
# new deviance for model 1
-2*sum(y_new*log(phat_m1) + (1-y_new)*log(1 - phat_m1))
# new deviance for model 2
-2*sum(y_new*log(phat_m2) + (1-y_new)*log(1 - phat_m2))
m1 <- glm(Dengue ~ Age + WBC + PLT, data = dengue,
family = binomial)
m2 <- glm(Dengue ~  Age + WBC + PLT + BMI + HCT + Temperature,
data = dengue, family = binomial)
print(paste("The change in deviance for model 1 is ", round(m1$null.deviance - m1$deviance, 2)))
print(paste("The change in deviance for model 2 is ", round(m2$null.deviance - m2$deviance, 2)))
pchisq(m1$deviance - m2$deviance, 3, lower.tail = F)
# calculating performance metrics using the ROCR package
## TPR vs. FPR for model 1
pred1 <- prediction(m1$fitted.values, m1$y)
perf1 <- performance(pred1,"tpr","fpr")
## TPR vs. FPR for model 2
pred2 <- prediction(m2$fitted.values, m2$y)
perf2 <- performance(pred2,"tpr","fpr")
## Plot both ROC curves on the same graph
data.frame(fpr = c(perf1@x.values[[1]], perf2@x.values[[1]]),
tpr = c(perf1@y.values[[1]], perf2@y.values[[1]]),
model = c(rep("Model 1", length(perf1@x.values[[1]])),
rep("Model 2", length(perf2@x.values[[1]])))) |>
ggplot(aes(x = fpr, y = tpr, color = model)) +
geom_line() +
geom_abline(slope = 1, intercept = 0, lty = 2) +
labs(x = "False positive rate (1 - Specificity)",
y = "True positive rate (Sensitivity)") +
theme_classic()
## calculate AUC values
performance(pred1, "auc")@y.values # AUC for model 1
performance(pred2, "auc")@y.values # AUC for model 2
set.seed(712)
n <- 1000
d <- 6
X <- matrix(rnorm(d*n), nrow=n)
p <- exp(-0.5 + X %*% c(0.2, 0.2, 0.2, 0, 0, 0))/(
1 + exp(-0.5 + X %*% c(0.2, 0.2, 0.2, 0, 0, 0))
)
y <- rbinom(n, 1, p)
m1 <- glm(y ~ X[,1:3], family = binomial)
m2 <- glm(y ~ X, family = binomial)
print(paste("The LRT generates a p-value of ", pchisq(m1$deviance - m2$deviance, 3, lower.tail = FALSE)))
print(paste("The LRT generates a p-value of ", round(pchisq(m1$deviance - m2$deviance, 3, lower.tail = FALSE), 3)))
print(paste("The LRT generates a p-value of ", round(pchisq(m1$deviance - m2$deviance, 3, lower.tail = FALSE), 3)))
print(paste("The deviance for model 1 is ", round(m1$deviance,2)))
print(paste("The deviance for model 2 is ", round(m2$deviance,2)))
print(paste("The LRT generates a p-value of ", round(pchisq(m1$deviance - m2$deviance, 3, lower.tail = FALSE), 3)))
m2$coefficients
# calculating performance metrics using the ROCR package
## TPR vs. FPR for model 1
pred1 <- prediction(m1$fitted.values, m1$y)
perf1 <- performance(pred1,"tpr","fpr")
## TPR vs. FPR for model 2
pred2 <- prediction(m2$fitted.values, m2$y)
perf2 <- performance(pred2,"tpr","fpr")
## Plot both ROC curves on the same graph
data.frame(fpr = c(perf1@x.values[[1]], perf2@x.values[[1]]),
tpr = c(perf1@y.values[[1]], perf2@y.values[[1]]),
model = c(rep("Model 1", length(perf1@x.values[[1]])),
rep("Model 2", length(perf2@x.values[[1]])))) |>
ggplot(aes(x = fpr, y = tpr, color = model)) +
geom_line() +
geom_abline(slope = 1, intercept = 0, lty = 2) +
labs(x = "False positive rate (1 - Specificity)",
y = "True positive rate (Sensitivity)") +
theme_classic()
## calculate AUC values
performance(pred1, "auc")@y.values # AUC for model 1
performance(pred2, "auc")@y.values # AUC for model 2
X_new <- matrix(rnorm(d*n), nrow=n)
p_new <- exp(-0.5 + X_new %*% c(0.2, 0.2, 0.2, 0, 0, 0))/(
1 + exp(-0.5 + X_new %*% c(0.2, 0.2, 0.2, 0, 0, 0))
)
y_new <- rbinom(n, 1, p_new)
# predictions on new observations
phat_m1 <- exp(m1$coefficients[1] + X_new[,1:3] %*% m1$coefficients[2:4])/(
1 + exp(m1$coefficients[1] + X_new[,1:3] %*% m1$coefficients[2:4])
)
phat_m2 <- exp(m2$coefficients[1] + X_new %*% m2$coefficients[2:7])/(
1 + exp(m2$coefficients[1] + X_new %*% m2$coefficients[2:7])
)
# new deviance for model 1
-2*sum(y_new*log(phat_m1) + (1-y_new)*log(1 - phat_m1))
# new deviance for model 2
-2*sum(y_new*log(phat_m2) + (1-y_new)*log(1 - phat_m2))
